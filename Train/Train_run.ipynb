{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import join,isfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import autograd\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models\n",
    "\n",
    "from misc_function import processImage, detail_enhance_lab, recreate_image, PreidictLabel, AdvLoss\n",
    "from module import DeepGuidedFilter\n",
    "from utils import Config\n",
    "from my_model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config, dataset_path, dataset_smooth_path, image_list, idx):\n",
    "    # 모델 저장\n",
    "    save_path = config.SAVE\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Adv img 폴더\n",
    "    adv_path =    '../AdvImg_mobilenet_v2/'\n",
    "    if not os.path.isdir(adv_path):\n",
    "        os.makedirs(adv_path)\n",
    "        \n",
    "    # 스무딩 loss\n",
    "    \n",
    "    criterion_L1 = nn.L1Loss()\n",
    "    criterion_L2 = nn.MSELoss()\n",
    "    optimizer = optim.Adam(config.model.parameters(), lr=config.LR)\n",
    "\n",
    "    with torch.cuda.device(0):\n",
    "        config.model.cuda()\n",
    "        criterion_L1.cuda()\n",
    "        criterion_L2.cuda()\n",
    "    # Load 모델\n",
    "    classifier = Model()\n",
    "    classifier.load_state_dict(torch.load(config.model_weight))\n",
    "\n",
    "    classifier.eval()\n",
    "    classifier.cuda()\n",
    "\n",
    "    # 모델 FC-layer 고정\n",
    "    for param in classifier.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    img_name = image_list[idx]\n",
    "    \n",
    "    # 원본이미지, 스무딩이미지 전처리하고 tensor로 바꿔줌.\n",
    "    x= processImage(dataset_path,img_name)    \n",
    "    gt_smooth = processImage(dataset_smooth_path,img_name)\n",
    "    \n",
    "    # 정답 class, logit\n",
    "    class_x, logit_x = PreidictLabel(x, classifier)\n",
    "\n",
    "    #FCNN 최대 iter 설정\n",
    "    maxIters = 5000\n",
    "\n",
    "\n",
    "    for it in range(maxIters): \n",
    "        t = time.time()\n",
    "        '''\n",
    "            gt_smooth : [11]로 스무딩된 이미지\n",
    "            x_smooth : 뉴럴네트워크를 이용해서 스무딩 하는법을 배움.\n",
    "        '''\n",
    "        with autograd.detect_anomaly():\n",
    "            # x를 guided filter에 넣고 smoothing 하는 방법을 배움. \n",
    "            x_smooth= config.forward(x, gt_smooth, config)\n",
    "            #디테일 강화\n",
    "            enh = detail_enhance_lab(x,x_smooth)           \n",
    "            # 디테일 강회 이미지 class, logit\n",
    "            class_enh, logit_enh = PreidictLabel(enh.permute(2,0,1).unsqueeze(dim=0), classifier)\n",
    "            \n",
    "            #smoothing, adv loss\n",
    "            loss1 = criterion_L2(x_smooth, gt_smooth)\n",
    "            loss2 = criterion_L1(x_smooth, gt_smooth)\n",
    "            loss3 = AdvLoss(logit_enh, class_x)\n",
    "                    \n",
    "            # smoothing_loss, Adv_loss 비율 설정\n",
    "            loss = 5*loss1 + 5*loss2 + loss3\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            if config.clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm(config.model.parameters(), config.clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            check_enh = recreate_image(enh)\n",
    "            check_enh = torch.from_numpy(np.flip(check_enh,axis=0).copy()).cuda()\n",
    "            class_enh, _ = PreidictLabel(check_enh.permute(2,0,1).unsqueeze(dim=0), classifier)\n",
    "\n",
    "            if (class_x != class_enh): \n",
    "                cv2.imwrite('{}{}'.format(adv_path,img_name), recreate_image(enh))\n",
    "                # 스무딩 loss. 값이 클수록 변형이 큼.\n",
    "                if (loss1< 0.0001):\n",
    "                    break\n",
    "\n",
    "    # Save the FCNN\n",
    "    torch.save(config.model.state_dict(), os.path.join(save_path, 'model_latest.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(imgs,gt, config):\n",
    "    x_hr= imgs\n",
    "    gt_hr=gt\n",
    "    return config.model(x_hr, x_hr)\n",
    "\n",
    "dataset_path  ='../Dataset/'\n",
    "dataset_smooth_path = '../Smoothing_Imgs/'\n",
    "\n",
    "default_config = Config(\n",
    "    N_START = 0,\n",
    "    N_EPOCH = 100,\n",
    "    SAVE = 'ckpt',\n",
    "    LR = 0.001,\n",
    "    # clip\n",
    "    clip = 0.01,\n",
    "    # model\n",
    "    model = DeepGuidedFilter(),\n",
    "    forward = None,\n",
    "    model_weight = '../save/mobilenet_v2.ckpt'\n",
    ")\n",
    "image_list =  [f for f in listdir(dataset_path) if isfile(join(dataset_path,f))]\n",
    "NumImg=len(image_list)\n",
    "# Configuration\n",
    "config = copy.deepcopy(default_config)\n",
    "config.forward = forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "  7%|▋         | 1/15 [14:42<3:25:53, 882.41s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 13%|█▎        | 2/15 [16:15<2:19:54, 645.71s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 20%|██        | 3/15 [18:02<1:36:48, 484.03s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 27%|██▋       | 4/15 [32:28<1:49:43, 598.53s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 33%|███▎      | 5/15 [38:16<1:27:15, 523.58s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 40%|████      | 6/15 [52:48<1:34:12, 628.09s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 47%|████▋     | 7/15 [57:13<1:09:13, 519.15s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 53%|█████▎    | 8/15 [1:11:13<1:11:46, 615.25s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 60%|██████    | 9/15 [1:12:15<44:56, 449.35s/it]  Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 67%|██████▋   | 10/15 [1:26:32<47:38, 571.65s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 73%|███████▎  | 11/15 [1:27:54<28:18, 424.67s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 80%|████████  | 12/15 [1:42:26<27:56, 558.92s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 87%|████████▋ | 13/15 [1:46:31<15:29, 464.83s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      " 93%|█████████▎| 14/15 [1:48:07<05:53, 353.94s/it]Using cache found in /home/kjwspecial/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "100%|██████████| 15/15 [2:02:40<00:00, 490.70s/it]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(range(NumImg)):\n",
    "    run(config, dataset_path, dataset_smooth_path, image_list, idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
