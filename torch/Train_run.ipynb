{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import join,isfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import autograd\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "from misc_function import processImage, detail_enhance_lab, recreate_image, PreidictLabel, AdvLoss\n",
    "from module import DeepGuidedFilter\n",
    "from my_model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(image, smooth_image, filename):\n",
    "    # Adv img 폴더\n",
    "    adv_path =    '../Adv_Img_mobilenet_v2/'\n",
    "    if not os.path.isdir(adv_path):\n",
    "        os.makedirs(adv_path)\n",
    "        \n",
    "    # 스무딩 loss\n",
    "    criterion_L1 = nn.L1Loss()\n",
    "    criterion_L2 = nn.MSELoss()\n",
    "    guided_model = DeepGuidedFilter()\n",
    "    optimizer = optim.Adam(guided_model.parameters(), lr=1e-3)\n",
    "\n",
    "    with torch.cuda.device(0):\n",
    "        guided_model.cuda()\n",
    "        criterion_L1.cuda()\n",
    "        criterion_L2.cuda()\n",
    "    # Load 모델\n",
    "    classifier = Model()\n",
    "    classifier.load_state_dict(torch.load('../model_weight/mobilenet_v2.ckpt'))\n",
    "\n",
    "    classifier.eval()\n",
    "    classifier.cuda()\n",
    "\n",
    "    # 모델 FC-layer 고정\n",
    "    for param in classifier.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    # 원본이미지, 스무딩이미지 전처리하고 tensor로 바꿔줌.\n",
    "    x= processImage(image)    \n",
    "    gt_smooth = processImage(smooth_image)\n",
    "    # 정답 class, logit\n",
    "    class_x, logit_x = PreidictLabel(x, classifier)\n",
    "\n",
    "    #FCNN 최대 iter 설정\n",
    "    maxIters = 5000\n",
    "\n",
    "    for it in range(maxIters): \n",
    "        ori_label = torch.tensor(int(filename.split('_')[2][0])).cuda()\n",
    "        if not torch.equal(ori_label, class_x):\n",
    "            break\n",
    "        '''\n",
    "            gt_smooth : [11]로 스무딩된 이미지\n",
    "            x_smooth : 뉴럴네트워크를 이용해서 스무딩 하는법을 배움.\n",
    "        '''\n",
    "        with autograd.detect_anomaly():\n",
    "            # x를 guided filter에 넣고 smoothing 하는 방법을 배움. \n",
    "            x_smooth = guided_model(x,x)\n",
    "            #디테일 강화\n",
    "            enh,base = detail_enhance_lab(x,x_smooth)           \n",
    "            # 디테일 강회 이미지 class, logit\n",
    "            class_enh, logit_enh = PreidictLabel(enh.permute(2,0,1).unsqueeze(dim=0), classifier)\n",
    "            \n",
    "            #smoothing, adv loss\n",
    "            loss1 = criterion_L2(x_smooth, gt_smooth)\n",
    "            loss2 = criterion_L1(x_smooth, gt_smooth)\n",
    "            loss3 = AdvLoss(logit_enh, class_x)\n",
    "            \n",
    "            # smoothing_loss, Adv_loss 비율 설정\n",
    "            loss = 5*loss1  + loss3 + 5*loss2\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "        \n",
    "            torch.nn.utils.clip_grad_norm(guided_model.parameters(), 0.01)\n",
    "            optimizer.step()\n",
    "            check_enh = recreate_image(enh)\n",
    "            check_enh = torch.from_numpy(np.flip(check_enh,axis=0).copy()).cuda()\n",
    "            class_enh, _ = PreidictLabel(check_enh.permute(2,0,1).unsqueeze(dim=0), classifier)\n",
    "            if it % 100 ==0:\n",
    "                print(f'iter : {it} \\t L2-loss:{loss1} \\t L1-loss:{loss2} \\t Adv_loss: {loss3}')\n",
    "            if (class_x != class_enh): \n",
    "                cv2.imwrite('{}{}'.format(adv_path,filename), recreate_image(enh))\n",
    "                if (loss1< 0.0005):\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=[]\n",
    "label=[]\n",
    "filename=[]\n",
    "for file_name in glob.glob('../Dataset/*.png'):\n",
    "    filename.append(file_name.split('/')[2])\n",
    "    label.append(file_name.split('_')[2][0])\n",
    "    image.append(plt.imread(file_name)[...,:3])\n",
    "image_set = list(map(lambda x: x, image))\n",
    "for idx in tqdm(range(0,len(image_set))):\n",
    "    smooth_image = plt.imread('../Smoothing_Imgs/'+filename[idx])\n",
    "    run(image_set[idx],smooth_image,filename[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
