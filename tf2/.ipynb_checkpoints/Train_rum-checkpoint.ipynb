{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/kjwspecial/anaconda3/envs/keras/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import join,isfile\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import copy\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, optimizers\n",
    "\n",
    "from misc_function import processImage, detail_enhance_lab, recreate_image, PreidictLabel, AdvLoss\n",
    "from module import DeepGuidedFilter\n",
    "from my_model import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(image, smooth_image, filename):\n",
    "    \n",
    "    # Adv img 폴더\n",
    "    adv_path =    '../Adv_Img_mobilenet_v2/'\n",
    "    if not os.path.isdir(adv_path):\n",
    "        os.makedirs(adv_path)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0005)\n",
    "\n",
    "    with open('../model_weight/model_20200507_9_1.00_0.0088','rb') as w:\n",
    "        weights = pickle.load(w)\n",
    "\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=[160, 160, 3], include_top=False,weights='imagenet')\n",
    "\n",
    "    # white-box model\n",
    "    model = Model(base_model)\n",
    "    model.build((None,160,160,3))\n",
    "    model.set_weights(weights)\n",
    "\n",
    "    guided_model = DeepGuidedFilter()#\n",
    "    \n",
    "    x= processImage(image)    \n",
    "    gt_smooth = processImage(smooth_image)\n",
    "    class_x, logit = PreidictLabel(x,model)\n",
    "    ####\n",
    "    maxIters = 5000\n",
    "    \n",
    "    for it in range(maxIters):\n",
    "        if not tf.math.equal(int(filename.split('_')[2][0]), class_x):\n",
    "            break\n",
    "            \n",
    "        with tf.GradientTape() as tape:\n",
    "            #tape.watch(x)     \n",
    "            x_smooth = guided_model(x,x)# x,gt_smooth\n",
    "            enh = detail_enhance_lab(x,x_smooth) \n",
    "            class_enh, logit_enh = PreidictLabel(tf.expand_dims(enh,axis=0), model)\n",
    "            \n",
    "            loss1 = losses.MSE(gt_smooth, x_smooth)\n",
    "            loss3 = losses.MAE(gt_smooth, x_smooth)\n",
    "            loss2 = AdvLoss(logit_enh, class_x)\n",
    "            loss = loss1*1000 + loss2 + loss3*500\n",
    "            \n",
    "            #recreat하는 과정에서 뭉개질수있기때문에, 복원한다음의 class값이랑 비교해야함.\n",
    "            ckeck_enh = recreate_image(enh)\n",
    "            class_enh,_ = PreidictLabel(np.expand_dims(enh,axis=0),model)\n",
    "            \n",
    "            if it % 20 ==0:\n",
    "                print(f'iter : {it} \\t loss:{tf.reduce_mean(loss1)} \\t Adv_loss: {loss2}')\n",
    "            if (class_x != class_enh):\n",
    "                cv2.imwrite('{}{}'.format(adv_path,filename), recreate_image(enh))\n",
    "                if(tf.reduce_mean(loss1)<0.0005):\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "            variables = guided_model.trainable_variables\n",
    "            gradients = tape.gradient(loss, variables)\n",
    "            optimizer.apply_gradients(zip(gradients, variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/400 [00:01<12:16,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter : 0 \t loss: tf.Tensor(0.10521057, shape=(), dtype=float32)\n",
      "iter : 20 \t loss: tf.Tensor(0.024035512, shape=(), dtype=float32)\n",
      "iter : 40 \t loss: tf.Tensor(0.015221684, shape=(), dtype=float32)\n",
      "iter : 60 \t loss: tf.Tensor(0.010079528, shape=(), dtype=float32)\n",
      "iter : 80 \t loss: tf.Tensor(0.008342746, shape=(), dtype=float32)\n",
      "iter : 100 \t loss: tf.Tensor(0.0074386103, shape=(), dtype=float32)\n",
      "iter : 120 \t loss: tf.Tensor(0.006581328, shape=(), dtype=float32)\n",
      "iter : 140 \t loss: tf.Tensor(0.0055891015, shape=(), dtype=float32)\n",
      "iter : 160 \t loss: tf.Tensor(0.0054657734, shape=(), dtype=float32)\n",
      "iter : 180 \t loss: tf.Tensor(0.004195231, shape=(), dtype=float32)\n",
      "iter : 200 \t loss: tf.Tensor(0.0033796025, shape=(), dtype=float32)\n",
      "iter : 220 \t loss: tf.Tensor(0.003072904, shape=(), dtype=float32)\n",
      "iter : 240 \t loss: tf.Tensor(0.0025126757, shape=(), dtype=float32)\n",
      "iter : 260 \t loss: tf.Tensor(0.002358365, shape=(), dtype=float32)\n",
      "iter : 280 \t loss: tf.Tensor(0.0023233138, shape=(), dtype=float32)\n",
      "iter : 300 \t loss: tf.Tensor(0.0018457015, shape=(), dtype=float32)\n",
      "iter : 320 \t loss: tf.Tensor(0.0016205773, shape=(), dtype=float32)\n",
      "iter : 340 \t loss: tf.Tensor(0.0014363162, shape=(), dtype=float32)\n",
      "iter : 360 \t loss: tf.Tensor(0.00169326, shape=(), dtype=float32)\n",
      "iter : 380 \t loss: tf.Tensor(0.0013220452, shape=(), dtype=float32)\n",
      "iter : 400 \t loss: tf.Tensor(0.0011554668, shape=(), dtype=float32)\n",
      "iter : 420 \t loss: tf.Tensor(0.0011286454, shape=(), dtype=float32)\n",
      "iter : 440 \t loss: tf.Tensor(0.0010367945, shape=(), dtype=float32)\n",
      "iter : 460 \t loss: tf.Tensor(0.0010352274, shape=(), dtype=float32)\n",
      "iter : 480 \t loss: tf.Tensor(0.000933038, shape=(), dtype=float32)\n",
      "iter : 500 \t loss: tf.Tensor(0.00091470516, shape=(), dtype=float32)\n",
      "iter : 520 \t loss: tf.Tensor(0.0008456009, shape=(), dtype=float32)\n",
      "iter : 540 \t loss: tf.Tensor(0.0008922693, shape=(), dtype=float32)\n",
      "iter : 560 \t loss: tf.Tensor(0.0007872665, shape=(), dtype=float32)\n",
      "iter : 580 \t loss: tf.Tensor(0.0012010306, shape=(), dtype=float32)\n",
      "iter : 600 \t loss: tf.Tensor(0.00083705445, shape=(), dtype=float32)\n",
      "iter : 620 \t loss: tf.Tensor(0.0007196063, shape=(), dtype=float32)\n",
      "iter : 640 \t loss: tf.Tensor(0.00068007945, shape=(), dtype=float32)\n",
      "iter : 660 \t loss: tf.Tensor(0.00070873834, shape=(), dtype=float32)\n",
      "iter : 680 \t loss: tf.Tensor(0.00064668694, shape=(), dtype=float32)\n",
      "iter : 700 \t loss: tf.Tensor(0.00061866955, shape=(), dtype=float32)\n",
      "iter : 720 \t loss: tf.Tensor(0.00070373534, shape=(), dtype=float32)\n",
      "iter : 740 \t loss: tf.Tensor(0.0005989835, shape=(), dtype=float32)\n",
      "iter : 760 \t loss: tf.Tensor(0.00057175977, shape=(), dtype=float32)\n",
      "iter : 780 \t loss: tf.Tensor(0.00064853503, shape=(), dtype=float32)\n",
      "iter : 800 \t loss: tf.Tensor(0.0005646128, shape=(), dtype=float32)\n",
      "iter : 820 \t loss: tf.Tensor(0.0005386569, shape=(), dtype=float32)\n",
      "iter : 840 \t loss: tf.Tensor(0.0006045397, shape=(), dtype=float32)\n",
      "iter : 860 \t loss: tf.Tensor(0.00052326976, shape=(), dtype=float32)\n",
      "iter : 880 \t loss: tf.Tensor(0.0007158372, shape=(), dtype=float32)\n",
      "iter : 900 \t loss: tf.Tensor(0.00057970005, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/400 [07:05<14:12:05, 128.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter : 0 \t loss: tf.Tensor(0.24574848, shape=(), dtype=float32)\n",
      "iter : 20 \t loss: tf.Tensor(0.038027152, shape=(), dtype=float32)\n",
      "iter : 40 \t loss: tf.Tensor(0.02695047, shape=(), dtype=float32)\n",
      "iter : 60 \t loss: tf.Tensor(0.02131784, shape=(), dtype=float32)\n",
      "iter : 80 \t loss: tf.Tensor(0.01645043, shape=(), dtype=float32)\n",
      "iter : 100 \t loss: tf.Tensor(0.013227451, shape=(), dtype=float32)\n",
      "iter : 120 \t loss: tf.Tensor(0.011410313, shape=(), dtype=float32)\n",
      "iter : 140 \t loss: tf.Tensor(0.009761511, shape=(), dtype=float32)\n",
      "iter : 160 \t loss: tf.Tensor(0.008790905, shape=(), dtype=float32)\n",
      "iter : 180 \t loss: tf.Tensor(0.007989739, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "image=[]\n",
    "label=[]\n",
    "filename=[]\n",
    "for file_name in glob.glob('../Dataset/*.png'):\n",
    "    filename.append(file_name.split('/')[2])\n",
    "    label.append(file_name.split('_')[2][0])\n",
    "    image.append(plt.imread(file_name)[...,:3])\n",
    "image_set = list(map(lambda x: x, image))\n",
    "for idx in tqdm(range(0,len(image_set))):\n",
    "    smooth_image = plt.imread('../Smoothing_Imgs/'+filename[idx])\n",
    "    run(image_set[idx],smooth_image,filename[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# image=[]\n",
    "# label=[]\n",
    "# filename=[]\n",
    "# for file_name in glob.glob('../Dataset/*.png'):\n",
    "#     filename.append(file_name.split('/')[2])\n",
    "#     label.append(file_name.split('_')[2][0])\n",
    "#     image.append(plt.imread(file_name)[...,:3])\n",
    "# image_set = list(map(lambda x: x, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in tqdm(range(5,len(image_set))):\n",
    "#     smooth_image = plt.imread('../Smoothing_Imgs/'+filename[idx])\n",
    "#     run(image_set[idx],smooth_image,filename[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
